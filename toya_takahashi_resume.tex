\documentclass[
	%a4paper,
	10pt,
]{resume}

\usepackage{ebgaramond}
\usepackage[hidelinks]{hyperref}

\name{Toya Takahashi}

\address{(907)~$\cdot$~538~$\cdot$~1519 \\ \href{mailto:toyat@mit.edu}{\underline{toyat@mit.edu}} \\ \href{https://www.linkedin.com/in/toya-takahashi/}{\underline{linkedin/toya-takahashi}} \\ \href{https://github.com/toyat522}{\underline{github/toyat522}} \\ Cambridge, MA}

\begin{document}

\begin{rSection}{Education}

	\textbf{Massachusetts Institute of Technology (M.I.T.)} \hfill \textit{Expected in May 2026} \\ 
	B.S. in Electrical Engineering and Computer Science | GPA: 5.0/5.0 \\
    Relevant Coursework: Robotic Manipulation, Autonomous Navigation, Accelerated Computing, Deep Learning, Controls, Operating Systems
\end{rSection}

\begin{rSection}{Experience}

    \begin{rSubsection}{MIT Sensing, Perception, Autonomy, and Robot Kinetics (SPARK) Lab}{September 2024 - Present}{Undergraduate Researcher}{Cambridge, MA}
    \item Integrated learning-based keypoint extraction with SuperGlue and LightGlue into a visual loop-closure module for SLAM.
    \item Built a software platform for mobile robots supporting RTK positioning and LiDAR-inertial odometry to generate maps using 3D scene graphs.
        \item Evaluated camera-LiDAR calibration algorithms to reduce reprojection errors and improve 3D scene mapping accuracy.
    \end{rSubsection}

	\begin{rSubsection}{MIT EECS Department}{February 2024 - Present}{Teaching Assistant / Lab Assistant}{Cambridge, MA}
    \item Guided students through labs on computer vision, state estimation, motion planning, and control using real robotic platforms.
    \item Assisted students with lab assignments on designing a pipelined RISC-V processor in the Minispec hardware description language.
	\end{rSubsection}

	\begin{rSubsection}{NVIDIA Isaac ROS}{May 2025 - August 2025}{Systems Software Robotics Solutions Intern}{Santa Clara, CA}
    \item Developed a CUDA-accelerated suite of Robot Operating System (ROS 2) nodes for running a TensorRT-optimized Grounding DINO open-set object detection model, including a text tokenizer, text and image tensor encoders, and an output tensor decoder with visualization.
    \item Implemented benchmarking scripts to measure latency and throughput of the Grounding DINO detection graph across multiple GPUs.
    \item Integrated Segment Anything (SAM, SAM2) and Grounding DINO into a robotic manipulator workflow using behavior trees to segment and detect arbitrary objects for perception-driven pick-and-place tasks.
    \item Implemented a C++ ROS node to align Realsense depth images from the IR to RGB frame, enabling deep-learning-enhanced stereo disparity matching for accurate pose estimation.
    \end{rSubsection}

	\begin{rSubsection}{MIT Arcturus Robotics}{September 2022 - March 2025}{Autonomy Software Team Co-Lead}{Cambridge, MA}
    \item Led a software team of approximately 20 students in developing an Autonomous Surface Vehicle (ASV) autonomy stack using C++ and Python with ROS 2 and Mission Oriented Operating Suite (MOOS-IvP) middlewares.
    \item Developed an algorithm to overlay clustered LiDAR point cloud onto the camera frame to match obstacles with detected objects.
    \item Implemented an Extended Kalman Filter to fuse GPS and IMU data for global robot localization with centimeter-level accuracy.
    \item Created a visual navigation algorithm for buoy traversal, integrating the YOLOv5 object detection model with a PID controller.
    \end{rSubsection}

	\begin{rSubsection}{NVIDIA Isaac ROS}{May 2024 - August 2024}{Systems Software Robotics Solutions Intern}{Santa Clara, CA}
    \item Enhanced an end-to-end robot manipulator object-following workflow by improving stability of object pose estimations from a deep neural network.
    \item Implemented ROS nodes for post-processing pose streams via averaging, stability analysis, outlier detection, and Kalman filtering.
    \item Developed and optimized a CUDA-accelerated alpha compositing ROS node, enabling efficient GPU-based image blending without redundant CPU-GPU memory transfers.
    \end{rSubsection}

	\begin{rSubsection}{MIT Sea Grant College}{January 2023 - May 2024}{Undergraduate Researcher}{Cambridge, MA}
    \item Modeled an oyster farm simulation environment in the Gazebo robotics simulator to test and validate an ASV autonomy stack.
    \item Created Unified Robot Description Format (URDF) and Simulation Description Format (SDF) files for ships, oyster baskets, and ocean waves to generate realistic simulation models.
    \item Designed and built a cross-hull electrical wiring system for integrating microcontrollers, stepper motors, and sensors.
    \end{rSubsection}

	%\begin{rSubsection}{MIT Media Lab: Signal Kinetics}{June 2023 - December 2023}{Undergraduate Researcher}{Cambridge, MA}
    %\item Operated the UR5e robot arm to collect millimeter-wave radar, OptiTrack motion capture, and camera data, contributing to the development of a robot designed to search for and retrieve hidden items.
    %\item Wrote C++ and Python scripts using data analysis packages such as NumPy and Matplotlib to construct a machine learning dataset of simulated and robot-collected radar images.
	%\end{rSubsection}

	%\begin{rSubsection}{MIT Code for Good}{October 2023 - February 2023}{Team Leader}{Cambridge, MA}
	%\item Led a team of 6 to develop a secure web application to collect and visualize client data on behalf of Thrive and Support Advocacy, a nonprofit organization supporting youth and adults with developmental disabilities.
	%\item Engineered user-friendly web interfaces with ReactJS for uploading survey results to the server and visualizing collected data.
    %\item Integrated front-end UI with back-end authentication and data handling systems using MongoDB, ExpressJS, and NodeJS.
	%\end{rSubsection}

	%\begin{rSubsection}{FIRST Robotics Competition}{September 2018 - May 2022}{Team President}{Anchorage, AK}
    %\item Awarded the 2021 FIRST Tech Challenge Dean's List for demonstrating leadership and technical expertise. Recognized among a global pool of over 121,000 participants.
    %\end{rSubsection}

\end{rSection}

\begin{rSection}{Technical Skills}

	\begin{tabular}{@{} >{\bfseries}l @{\hspace{6ex}} l @{}}
		Computer Languages & Python, C/C++, NumPy, CUDA, JavaScript, MATLAB, SystemVerilog, RISC-V Assembly \\
		Tools & Git, Docker, Linux, Robot Operating System (ROS), PyTorch, Drake, GTSAM, Computer-Aided Design (CAD)
	\end{tabular}

\end{rSection}

\end{document}
